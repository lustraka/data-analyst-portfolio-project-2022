{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "20211111_Scrape_WebPages_Root.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lustraka/data-analyst-portfolio-project-2022/blob/main/code/20211111_Scrape_WebPages_Root.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCZquV4HQ2R9"
      },
      "source": [
        "# Scrape Web Pages From a Google Search\n",
        "## Background\n",
        "### Purpose\n",
        "Purpose of this code is to scrape results of the google search and store it into an SQlite database.\n",
        "### Input\n",
        "Query: `data analytics portfolio projects`\n",
        "### Output\n",
        "\n",
        "A Data Set Stucture:\n",
        "\n",
        "Variable | Description\n",
        "-|-\n",
        "id | An unique idenitifier starting with `WP`.\n",
        "title | A title of the web page retrieved from the google search results.\n",
        "url | A URL of the web page retrieved from the google search.\n",
        "status | A statuts of the `requests`' response object.\n",
        "status_ts | A datetime of the web page scraping.\n",
        "text | A raw text of the response (body.text) if status == 200.\n",
        "text_len | The lenght of the text extracted from the page.\n",
        "\n",
        "The dataset is named 'wp_root' and stored in the SQLite database named `dapp2022.db`.\n"
      ],
      "id": "oCZquV4HQ2R9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87h-gyLDNR0C"
      },
      "source": [
        "# Import dependencies\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re"
      ],
      "id": "87h-gyLDNR0C",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miI7qzz9Vmkb"
      },
      "source": [
        "## Gather URLs Returned by the Google Search"
      ],
      "id": "miI7qzz9Vmkb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pFQ_dMJNUq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb9d2ce-be6b-45f0-8d64-4555fde2cb77"
      },
      "source": [
        "# Gather results of the google search\n",
        "goo_urls = [\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&oq=data&aqs=chrome.0.69i59j69i57j69i59l2j46i199i291i512j0i512j46i199i465i512l2j0i512j46i199i465i512.11687j0j15&sourceid=chrome&ie=UTF-8',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvIv9xMqnEX0ovFt11T6fuyM3M4Mfg:1636633175528&ei=VwqNYfGxH_6Oxc8P0p2iMA&start=10&sa=N&ved=2ahUKEwixubfYpZD0AhV-R_EDHdKOCAYQ8tMDegQIARA4&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvJxKspQaYOd2cHQYRiU1Sf8QhxyTg:1636633222254&ei=hgqNYczXDu2Fxc8P5q6tOA&start=20&sa=N&ved=2ahUKEwjMstvupZD0AhXtQvEDHWZXCwc4ChDy0wN6BAgBEDo&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvKSYC5n5JEBpCy1JS03A8TfWmEpDA:1636633242644&ei=mgqNYcnVJv-Jxc8Ph-yROA&start=30&sa=N&ved=2ahUKEwjJirj4pZD0AhX_RPEDHQd2BAc4FBDy0wN6BAgBEDw&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvJ3lAHBLk3KNhRouzNegD1l-pAc_A:1636633280596&ei=wAqNYf_fI9aGxc8P8cmyMA&start=40&sa=N&ved=2ahUKEwj_v8SKppD0AhVWQ_EDHfGkDAY4HhDy0wN6BAgBED0&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvIkIcBAQyog6AgIXogehS8vXyzFbQ:1636633296603&ei=0AqNYcuWJIuHxc8Pn7ipOA&start=50&sa=N&ved=2ahUKEwjLvpWSppD0AhWLQ_EDHR9cCgc4KBDy0wN6BAgBED8&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvIQJjKphf0kB1gq1GPaRGmIpt7pCQ:1636633311550&ei=3wqNYYGIIY6Sxc8P5IO0OA&start=60&sa=N&ved=2ahUKEwjB86WZppD0AhUOSfEDHeQBDQc4MhDy0wN6BAgBEEE&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvLmYcP9Aba0cs-KxtNJLa4gWnW0hw:1636633329250&ei=8QqNYYa-DumSxc8PjJ2WGA&start=70&sa=N&ved=2ahUKEwjG-t2hppD0AhVpSfEDHYyOBQM4PBDy0wN6BAgBEEQ&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvILi0x00qM4HGKBdbscmnlLzGWucw:1636633364526&ei=FAuNYffDH6aXxc8Pxv67OA&start=80&sa=N&ved=2ahUKEwj3nceyppD0AhWmS_EDHUb_Dgc4RhDy0wN6BAgBEEE&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvKCuhyPCC8b-XqKIughGMfRyUokpQ:1636633394668&ei=MguNYe6OKICXxc8PtuO0OA&start=90&sa=N&ved=2ahUKEwju7_bAppD0AhWAS_EDHbYxDQc4UBDy0wN6BAgBEEE&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvLmUEYA6FytS6bbDZuFqvnnm0eXKA:1636633424507&ei=UAuNYYqnHpOHxc8Pha26OA&start=100&sa=N&ved=2ahUKEwiKj5TPppD0AhWTQ_EDHYWWDgc4WhDy0wN6BAgBEEE&biw=1265&bih=1287&dpr=1',\n",
        "            'https://www.google.com/search?q=data+analytics+portfolio+projects&rlz=1C1GCEA_enCZ869CZ869&sxsrf=AOaemvLySR9z6lLw5QkWZKZYUihdQ9rnng:1636633438638&ei=XguNYdSWHsGQxc8P-Mij8As&start=110&sa=N&ved=2ahUKEwjUverVppD0AhVBSPEDHXjkCL44ZBDy0wN6BAgBEEI&biw=1265&bih=1287&dpr=1',\n",
        "            ]\n",
        "print(f'Here are {len(goo_urls)} URLs with results of a google search.')"
      ],
      "id": "_pFQ_dMJNUq6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 12 URLs with results of a google search.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6etC_r2cVjqK"
      },
      "source": [
        "## Scrape URLs Returned by the Google Search\n",
        "**An algorithm in a pseudocode**:\n",
        "```\n",
        "for each goo_url in goo_urls:\n",
        "    extract title and wp_url of the search result\n",
        "    for each wp_url extracted:\n",
        "        get response and timestamp\n",
        "        if response.status == 200:\n",
        "            save body.text and its length\n",
        "        else:\n",
        "            save empty string and 0\n",
        "        save gathered observation\n",
        "identify observations and save the data set\n",
        "```\n",
        "To extract a title and a url of web pages found by the google search\n",
        "- get the response of the `goo_url` and create a soup object\n",
        "```python\n",
        "gpage = requests.get(goo_url)\n",
        "gsoup = BeautifulSoup(gpage.content, 'html.parser')\n",
        "```\n",
        "- find elements with search results within the `gsoup` (titles are in the **h3** tags)\n",
        "```python\n",
        "gsoup.find_all('h3')\n",
        "```\n",
        "- extract title and url related to this **h3** tag\n",
        "```python\n",
        "for each h3 in gsoup.find_all('h3'):\n",
        "  title = h3.text\n",
        "  wp_url = re.search(r'q=(.*?)&', h3.parent['href']).group(1)\n",
        "```\n",
        "\n",
        "To scrape the text of the web page on `wp_url`:\n",
        "- get the response and its status code\n",
        "```python\n",
        "page = requests.get(wp_url)\n",
        "status = page.status_code\n",
        "status_ts = pd.Timestamp.today()\n",
        "```\n",
        "- extract text and its length if status code is 200 and the url is not of a pdf file otherwise impute empty values\n",
        "```python\n",
        "if status == 200 and wp_url[-3:] != \"pdf\"):\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  if soup.body: # check that html.parser succeeded\n",
        "    text = soup.body.text\n",
        "    text_len = len(text)\n",
        "  else:\n",
        "    text, text_len = '', 0\n",
        "else:\n",
        "  text, text_len = '', 0\n",
        "```\n",
        "\n",
        "To store the results:\n",
        "- append objects to the list\n",
        "- create a dataframe from the list\n",
        "- initialize identifiers\n",
        "- create SQLAlchemy engine and empty database\n",
        "- store dataframe in the database"
      ],
      "id": "6etC_r2cVjqK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH5k-bfpanx8"
      },
      "source": [
        ""
      ],
      "id": "MH5k-bfpanx8",
      "execution_count": null,
      "outputs": []
    }
  ]
}